<!DOCTYPE html>
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width">
<style>

@import url(https://fonts.googleapis.com/css?family=Yanone+Kaffeesatz:400,700);
@import url(https://fonts.googleapis.com/css?family=Contrail+One:400,700);

</style>
<link rel="stylesheet" type="text/css" href="./library/common.css" />
<link rel="stylesheet" type="text/css" href="./library/screen.css" media="screen" />
<link rel="stylesheet" type="text/css" href="./library/print.css" media="print" />
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
      processEscapes: true
    },
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js"></script>

</head>
<section style="text-align:center;padding-top:5em;">
  <h1><span class="green">Réseau de neuronnes et apprentissage profond</span></h1></br> <h2><p class="grey">intro ml,</h2>
  <a href="http://www.twiter.com/comeetie">@comeetie</a>
</section>



<section>
<h1 class="green" >ML</h1>
<h2> Grande classe de problèmes </h2>
<ul>
<li> Apprentissage supervisé 
$$\{(\mathbf{x}_1,y_1),...,(\mathbf{x}_n,y_n)\}\rightarrow\, f(\mathbf{x})\approx y$$
<li> Apprentissage non supervisé 
$$\{\mathbf{x}_1,...,\mathbf{x}_n\}\rightarrow\, f(\mathbf{x}) ?$$
</ul>
</section>
<section>
<h1 class="green" >ML</h1>
<h2> Grande classe de problèmes </h2>
Mais aussi :
<ul>
<li> Apprentissage semi-supervisé 
$$\{(\mathbf{x}_1,y_1),...,(\mathbf{x}_n,y_n)\}+\{\mathbf{x}_1,...,\mathbf{x}_m\}\rightarrow\,f(\mathbf{x})\approx y$$
<li> Apprentissage auto-supervisé 
$$\{\mathbf{x}_1,...,\mathbf{x}_n\}\rightarrow \{(\mathbf{x}_1,\tilde{y}_1),...,(\mathbf{x}_n,\tilde{y}_n)\}\rightarrow\,f(\mathbf{x})\approx \tilde{y}$$
<li> Apprentissage par renforcement $$R(a_t,\mathbf{x}_t)$$
</ul>
</section>


<section>
<h1 class="green" >Apprentissage supervisé </h1>
<ul>
<li> Des entrées dans un espace de départ (feature space) $\mathcal{X}$
<li> Des sorties dans un espace d'arrivé (target space) $\mathcal{Y}$</ul>
</ul>
<h2 class="red"> Objectif</h2>
Trouver la fonction de liens 
$$f:\mathcal{X}\rightarrow\mathcal{Y}$$
ou la loi conditionelle $p(y|\mathbf{x})$ entre les entrées et les sorties.
</section>


<section>
<h1 class="green" >Apprentissage supervisé </h1>
Espace des hypoythèses:
<ul>
<li> La fonction $f$ appartient a une famille de fonction $\mathcal{H}$ qui dépend de la méthode (SVM, MLP, Decision Tree, Random Forest,...):
$f\in\mathcal{H}$
<li> Trouver la meilleure fonction $f$ parmis la famille $\mathcal{H}$
</ul>
<h2 class="red"> Objectif, minimiser l'erreur de généralisation</h2>
$$R(f)=\mathbb{E}_{\mathcal{X},\mathcal{y}}[L(f(\mathbf{x}),y)]=\int_{\mathcal{X}}\int_{\mathcal{y}}L(f(\mathbf{x}),y)p(\mathbf{x},y)d\mathbf{x}dy$$
$L(.,.)$ : fonction de perte (loss function) permetant de quantifier l'erreur comise lors de la prediction
</section>


<section>
<h2 class="red">Régression, fonction de perte :</h2>
$\mathcal{Y}=\mathbb{R}$, erreur quadratique :
$L(f(\mathbf{x},y)=(f(\mathbf{x})-y)^2$
<img src="./images/kernel_ridge.png" height="55%" style="margin-top:1em">
Ex: $y$ : consomation éléctrique, $\mathbf{x}$ : températures, heures, dates ,.... 
</section>

<section>

<h2 class="red">Classification, fonction de perte :</h2>
$\mathcal{Y}=\{0,1\}$ (de manière + générale = un ensemble discret de valeures possibles), erreur de classification :
$L(f(\mathbf{x}),y)=\mathbf{1}_{f(\mathbf{x})\neq y}$
<img src="./images/ex_classif.png" height="55%" style="margin-top:1em">
</br>
Ex: $y:\{spam, notspam\}$, $\mathbf{x}$ : données et meta-données d'un e-mail
</section>
<section>
<h2 class="red">Classification, fonction de perte :</h2>
$\mathcal{Y}=\{0,1\}$ (de manière + générale = un ensemble discret de valeures possibles), erreur de classification :
$L(f(\mathbf{x}),y)=\mathbf{1}_{f(\mathbf{x})\neq y}$
<img src="./images/imagenet.png" height="55%" style="margin-top:1em">
</br>
Ex: $y:\{leopard,porte\,conteneurs,...\}$, $\mathbf{x}$ : image
</section>
<section>
<h2 class="red">Classification, fonction de perte :</h2>
$\mathcal{Y}=\{0,1\}$ (de manière + générale = un ensemble discret de valeures possibles), erreur de classification :
$L(f(\mathbf{x}),y)=\mathbf{1}_{f(\mathbf{x})\neq y}$
<img src="./images/pascal.png" height="55%" style="margin-top:1em">
</br>
Ex: $y:\{cheval, personne,voiture,...\}^{D\times D}$, $\mathbf{x}$ : image
</section>

<section>
<h2 class="red">Classification, fonction de perte :</h2>
$\mathcal{Y}=\{0,1\}$ (de manière + générale = un ensemble discret de valeures possibles), erreur de classification :
$L(f(\mathbf{x}),y)=\mathbf{1}_{f(\mathbf{x})\neq y}$
<img src="./images/flickr.png" widtht="85%" style="margin-top:1em">
</br>
Ex: $y$:phrases de longueurs variables, $\mathbf{x}$ : image
</section>


<section>
<h2 class="red">Risque empirique</h2>
Un ensemble de données :
$S=(\mathbf{x},y):\{(\mathbf{x}_1,y_1),...,(\mathbf{x}_n,y_n)\}$
$$R_S(f)=\frac{1}{n}\sum_{i=1}^nL(f(\mathbf{x}_i),y_i)$$
$$\mathbb{E}[R_S(f)]=R(f)$$
</section>

<section>
<h2 class="red">Minimisation du risque empirique</h2>
La fonction $f$ est paramètrée par un ensmble de paramètres $\color{red}{\mathbf{w}}$, 
$$f(\mathbf{x};\color{red}{\mathbf{w}})$$
Sélection de la fonction $f$ (et donc des paramètres $\color{red}{\mathbf{w}}$) qui minimise le risque sur un ensemble de données
$$\color{red}{\mathbf{\hat{w}}}=\arg\min_{\color{red}{\mathbf{w}}}R_{S_a}(\color{red}{\mathbf{w}})=\arg\min_{\color{red}{\mathbf{w}}}\frac{1}{n}\sum_{i=1}^nL(f(\mathbf{x}_i,\color{red}{\mathbf{w}}),y_i)$$
</section>


<section>
<h1 class="green" >Apprentissage supervisé</h1>
<h3> Ensemble d'apprentissage / Ensemble de test</h3>
$f(\mathbf{x})=f(\mathbf{x},\color{red}{\mathbf{w}})$ peut être plus ou moins compliquée, avoir plus ou moins de degré de liberté.
<img src="./images/biais_variance.png" height=50%>
<span class="red"> ! a ne pas apprendre par coeur les données d'apprentissage
</section>


<section>
<h1 class="green" >Un peu plus compliqué !</h1>
<h3> Ensemble d'apprentissage / Ensemble de test</h3>
$f(\mathbf{x})=f(\mathbf{x},\color{red}{\mathbf{w}})$ peut être plus ou moins compliquée, avoir plus ou moins de degré de liberté.
<img src="./images/doubledescente.png" height=50%>
<span class="red"> ! pour certains modèles (type NN)  + SGD, 2 régimes 
</section>

<section>
<h1 class="green" >Apprentissage supervisé en pratique</h1>
<h2 class="red"> Données :</h2>  
Ensemble de couples $(\mathbf{x},y):\{(\mathbf{x}_1,y_1),...,(\mathbf{x}_n,y_n)\}$ divisé en plusieur parties: </br></br>
<ul>
<li> Ensemble d'apprentissage ($S_a$, permet de trouver $f$)
<li> Ensemble de test ($S_t$, permet d'évaluer $f$)
<li> Ensemble de validation ($S_v$, permet de choisir les hyper-paramètre de faire varier $\mathcal{H}$)
</ul>
</section>


<section>
<h1 class="green" >Apprentissage supervisé régularisation</h1>
$$\hat{\mathbf{w}}=\arg\min_{\mathbf{w}}\frac{1}{n}\sum_{i=1}^nL(f(\mathbf{x}_i,\mathbf{w}),y_i)+\color{red}{\lambda}.\color{green}{\Omega(\mathbf{w})}$$

<ul>
<li> $L$ : fonction de perte
<li> $\color{green}{\Omega}$ : est un terme de régularisation permettant de controler la capacité du modèle
<li> $\color{red}{\lambda}$ : hyper-paramètre controlant le degré de régularisation  
</ul>

</section>

<section>
<h2 class="green"> Exemple ridge regression</h2>
$$\arg\min_{\mathbf{w}}||\mathbf{Y}-\mathbf{X}\mathbf{w}||^2+\color{red}{\lambda}\color{green}{||\mathbf{w}||}$$
solution: $\mathbf{w}(\lambda)=(\mathbf{X}^t\mathbf{X}+\color{red}{\lambda}\color{green}{\mathbf{I}})^{-1}\mathbf{X}^t\mathbf{Y}$
<img src="./images/regL2.png" height="55%">
</section>

<section>
<h2 class="green"> Exemple Lasso</h2>
$$\arg\min_{\mathbf{w}}||\mathbf{Y}-\mathbf{X}\mathbf{w}||^2+\color{red}{\lambda}\color{green}{\sum_{d=1}^D|\mathbf{w}_d|}$$
Conséquence : solution parcimonieuse (sparse) 
<img src="./images/regL1.png" height="55%">
</section>

<section style="padding-top:5em;text-align:center">
<h1 class="green">NN</h1>
</section>

<section style="padding-top:5em;text-align:center">
<h1 class="green">Neural Networks</h1>
</section>


<section>
<h2> Un peu d'histoire</h2>
<ul>
<li>1943 : Formal neuron (Mc Culloch & Pitts)
<li>1957 : Perceptron (Rosenblatt)
<li>1969 : Limitation of the perceptron (Minsky & Papert)
<li>1974 : Gradient back-propagation (Werbos, pas de difusion) 
<li> 1986 : Gradient back-propagation bis (Rumelhart & McClelland, Lecun)
<ul>
<li> Nouvelles architectures CNN
<li> Nouvelles applications (Character recognition, Speech recognition and synthesis, Vision (image processing) CNN
</ul>
<li> 1997 : LSTM (Hochreiter & Schmidhuber) 
<li> 2005 : Deep networks (Hinton & Salakhutdinov, 2006)
<li> 2010 : auto-differentiation (Theano, Bengio & al)
<li> 2014 : Generative Adversarial Networks, GAN (Goodfellow & al)
</ul>
</section>

<section>
<h1 class="green" >Neuronne formel ?</h1>

McCulloch, W. S., Pitts, W., A Logical Calculus of the Ideas Immanent in Nervous Activity, Bulletin of Mathematical Biophysics, vol. 5, pp. 115-133, 1943.

$$\mathbb{R}^p\rightarrow\mathbb{R}$$

$$s=\Phi(\mathbf{x}^t\mathbf{w}+b)$$

Transformation linéaire suivie d'une transformation non-linéaire $\Phi$ :
<ul>
  <li> signaux d'entrées : $[x_1,...x_p]$ </li>
  <li> poids  : $[w_1,...,w_p]$ et biais : $b$ (mémoire)</li>
  <li> fonction d'activation : $\Phi$</li>
  <li> signal de sortie : $s$ </li>
</ul>

<h3 class="red"> Brique de base pour construire des réseau</h3>

</section>

<section >
<h1 class="green" >Neuronne formel ?</h1>


$$\Phi(\mathbf{w}^t\mathbf{x}+b)$$

Transformation linéaire suivie d'une transformation non-linéaire $\Phi$ :
<ul>
  <li> tangente hyperbolique $\Phi(x)$ : $tanh(x)$ </li>
  <li> sigmoid $\Phi(x)$ : $1/(1+\exp(- x))$</li>
  <li> relu $\Phi(x)$ : $max(0,x)$</li>
  <li> ...
  <li> softmax (vectorielle) : $\Phi(\mathbf{x})$ : $[\frac{\exp(\mathbf{x}_1)}{\sum_{k=1}^K\exp(\mathbf{x}_k)},...,\frac{\exp(\mathbf{x}_K)}{\sum_k={1^K}\exp(\mathbf{x}_k)}]$ </li>
</ul>

<h3 class="red"> Brique de base pour construire des réseaux</h3>

</section> 


<section >
<h1 class="green" >Fonction d'activation</h1>


<h3 class="red"> Tangeante hyperbolique </h3>
<img src="./images/Activation_tanh.svg" height="50%"></img>

</section> 

<section >
<h1 class="green" >Fonction d'activation</h1>

<h3 class="red"> Sigmoide </h3><img src="./images/Activation_logistic.svg" height="50%"></img>

</section> 

<section >
<h1 class="green" >Fonction d'activation</h1>


</h3><h3 class="red"> ReLu </h3>
<img src="./images/Activation_rectified_linear.svg" height="50%"></img>

</section> 



<section >

<h1 class="green" >Apprentissage supervisé</h1>
Perceptron Multi-couche. Agencement des neurones en couches des <span class="red">entrées $\mathbf{x}$</span> aux <span class="green">sorties $\mathbf{y}$</span>
<img src="./images/Colored_neural_network.svg" height="40%"></img>
Ensemble des poids : $\mathbf{W} = [(\mathbf{w}^1,b^1)...,(\mathbf{w}^M,b^m)]$
</section>

<section >
<h1 class="green" >MLP</h1>
Perceptron Multi-couche. Agencement des neurones en couches des <span class="red">entrées $\mathbf{x}$</span> aux <span class="green">sorties $\mathbf{y}$</span>
<img src="./images/Colored_neural_network.svg" height="40%"></img>
$$G(\mathbf{x},\mathbf{W})_r=\Phi^2(b_r^2+\sum_{q=1}^Qw_{rq}^2\Phi^1(b_q^1+\sum_{p=1}^Pw_{qp}^1x_{p}))$$
</section>


<section >
<h1 class="green" >MLP</h1>
Perceptron Multi-couche. Agencement des neurones en couches des <span class="red">entrées $\mathbf{x}$</span> aux <span class="green">sorties $\mathbf{y}$</span>
<img src="./images/Colored_neural_network.svg" height="40%"></img>
$$G(\mathbf{x},\mathbf{W})=\Phi^2(\mathbf{W}^2\Phi^1(\mathbf{W}^1x))$$
</section>

<section >
<h1 class="green" >MLP</h1>
Perceptron Multi-couche. Agencement des neurones en couches des <span class="red">entrées $\mathbf{x}$</span> aux <span class="green">sorties $\mathbf{y}$</span>
<img src="./images/Colored_neural_network_2.svg" height="40%"></img>
$$G(\mathbf{x},\mathbf{W})_r=\Phi^3(b_r^3+\sum_{q=1}^Qw_{rq}^3\Phi^2(b_r^2+\sum_{q=1}^Qw_{rq}^2\Phi^1(b_q^1+\sum_{p=1}^Pw_{qp}^1x_{p})))$$
</section>

<section >
<h1 class="green" >MLP</h1>
Perceptron Multi-couche. Agencement des neurones en couches des <span class="red">entrées $\mathbf{x}$</span> aux <span class="green">sorties $\mathbf{y}$</span>
<img src="./images/Colored_neural_network_2.svg" height="40%"></img>
$$G(\mathbf{x},\mathbf{W})=\Phi^3(\mathbf{W}^3\Phi^2(\mathbf{W}^2\Phi^1(\mathbf{W}^1x)))$$
</section>



<section >

<h1 class="green" >Réseau : Perceptron Multi-couche</h1>
<span class="red">Architecture :</span>
<ul>
<li> Nombre de couches 
<li> Taille des couches
<li> Type de fonction d'activation
<li> Régularisation
<li> <span class="red">Fonction de  perte</span>
<ul>
<li> Regression : mse $L=\sum_{i=1}^N||G(\mathbf{x}_i)-y_i||^2$, mae $L=\sum_{i=1}^N|G(\mathbf{x}_i)-y_i|$ 
<li> Classification : cce $L=-\sum_{i=1}^N(y_i\log(G(\mathbf{x}_i))+(1-y_i)log(1-G(\mathbf{x}_i)))$
</ul>
<li>Dernière couche activation 
<ul>
<li> Regression : lineaire
<li> Classification : sigmoid (binaire), soft-max (mulitclass) 
<ul>
</section>

<section >

<h1 class="green" >Réseau : Perceptron Multi-couche</h1>
<h3 class="red">Apprentissage</h3>
<ul>
<li> Optimisation des poids pour minimiser $L(G(\mathbf{x},\mathbf{w}),y))$ sur un jeu de données d'apprentissage$\{(x_1,y_1),...,(x_n,y_n)\}$
<li> Descente de gradient stochastique
<li> Calcul du gradient par retropopagation // derivées des fonctions composées 
$$f(g(x))'=f'(g(x))g'(x)$$
</ul>
</section>

<section >
<h3>Descente de gradient, règle de mise a jour :</h3>
$$\mathbf{w} \leftarrow \mathbf{w}-\color{red}\lambda\frac{\delta L(\mathbf{w})}{\delta \mathbf{w}}$$
<img src="./images/gradient.png" height="65%"></img>
</section>


<section >

<h3>Descente de gradient, règle de mise a jour :</h3>

$$\mathbf{w} \leftarrow \mathbf{w}-\color{red}\lambda\frac{\delta L(\mathbf{w})}{\delta \mathbf{w}}$$
<ul>
<li> calcul du gradient $\frac{\delta L(\mathbf{w})}{\delta \mathbf{w}}$
<li> mise a jour des poids en faisant un pas de longueur $\color{red}{\lambda}$
<li> dans la direction oppposée au gradient 
<li> // direction de plus grande pente 
<li> itérer jusqu'a convergence
<ul>
</section>

<section >

<h3>Descente de gradient</h3>

Initialiser $\mathbf{w}_1$ et $\lambda=0.001$, $\alpha=0.1,L_{old}=-\infty$</br></br>
Tant que $|L(\mathbf{w}_{n})-L_{old}|>\epsilon$:
<ul>
<li> mise a jour des poids :
$$\mathbf{w}_{n+1} \leftarrow \mathbf{w}_n-\color{red}\lambda\frac{\delta L(\mathbf{w}_n)}{\delta \mathbf{w}}$$
<li> $L_{old} \leftarrow L(\mathbf{w}_n)$
<li> test de décroissance si $L(\mathbf{w}_{n+1}) > L_{old}$
<ul>
<li> dimininution du pas $\lambda \leftarrow\lambda\alpha$ 
<li>retour à l'étape précédente
</ul>
<li> $n\leftarrow n+1$
<ul>
</section>


<section>
<img src="images/grad1.png" width="60%"></img>
Problème convexe
</section>

<section>
<img src="images/grad2.png" width="60%"></img>
Problème non convexe $\rightarrow$ minimum local
</section>


<section>
<img src="images/grad3.png" width="60%"></img>
Problème convexe
</section>

<section>
<img src="images/grad4.png" width="60%"></img>
Problème non convexe $\rightarrow$ minimum local (solution dépendante de l'initialisation)
</section>

<section>
<img src="images/grad5.png" width="60%"></img>
Problème non convexe $\rightarrow$ minimum local (solution dépendante de l'initialisation)
</section>

<section >

<h1>Descente de gradient stochastique</h1>
$$\frac{1}{\color{green}{n_b}}\sum_{i \in \color{green}{\mathbb{B}_j}} L(G(\mathbf{x}_i,\mathbf{w}),y_i) \approx \frac{1}{N} \sum_{i=1}^N L(G(\mathbf{x}_i,\mathbf{w}),y_i)$$

<ul>
<li> Faire $m$ balayage du jeu de données (epochs) 
<li> réordonner aléatoirement le jeu de données a chaque époque
<li> decouper en sous ensemble de données (mini-batch $\color{green}{\mathbb{B}_j}$) de taille $\color{green}{n_b}$
<li> mettre a jour les poids avec le gradient calculer avec chaque mini-batch
<li> itérer jusqu'au balayage complet
</ul>
</br>
<span class="red">Online gradient, mini-batch de taile $n_b=1$</span></br>
<span class="red">$\Rightarrow$Faible complexité, fonctionne sur de gros jeux de données </span></br>

</section>

<section>
<h1>Momentum</h1>
<span class="red">$\Rightarrow$Variante faisant intervenir la dynamique des vecteurs de mise a jour :</br>
 rmsprop, Adam,...</span>
$$
\begin{align}
\mathbf{z}_{n+1} &= \beta \mathbf{z}_{n} + \frac{\delta L(\mathbf{w})}{\delta \mathbf{w}}\nonumber\\
\mathbf{w}_{n+1} &= \mathbf{w}_{n} -\lambda \mathbf{z}_{n+1}\nonumber
\end{align}
$$
Pour plus d'information
<ul>
<li><a href="https://distill.pub/2017/momentum/">https://distill.pub/2017/momentum/</a>
<li><a href="https://ruder.io/optimizing-gradient-descent/">https://ruder.io/optimizing-gradient-descent/</a>
</ul>
</section>


<section style="padding-top:5em;text-align:center">
<h1 class="green">BP </h1>
</section>
<section style="padding-top:5em;text-align:center">
<h1 class="green">Back Propagation </h1>
</section>

<section >
<h1 class="red">Back Propagation</h1>
<h2 class="green">Objectif </h2>
$\Rightarrow$ calculer de manière efficace le gradient</br>
<h2 class="green">Fonctionement</h2>
Fonctionne en deux phases successives :
<ul> 
<li>Forward, <span class="red">entrées </span> aux <span class="green">sorties</span> :</br>
$\Rightarrow$  permet de calculer efficacement les sorties de chaques couches
<li>Backward, des <span class="green">sorties</span> aux <span class="red">entrées </span> :</br>
$\Rightarrow$  permet de calculer efficacement le gradient des poids de chaques couches
</ul>
</section>

<section>
<h1>Forward, des <span class="red">entrées </span> aux <span class="green">sorties</span></h1>
<img src="./images/Colored_neural_network_anim1.svg" height="50%"></img>
$$\color{red}{\mathbf{x}}\in\mathbb{R}^P$$
</section>

<section>
<h1>Forward, des <span class="red">entrées </span> aux <span class="green">sorties</span></h1>
<img src="./images/Colored_neural_network_anim2.svg" height="50%"></img>
$$\color{blue}{\mathbf{s}^1}\leftarrow \left[\Phi^1(\sum_p w_{1p}^1\color{red}{x_{p}} + b^1_1),...,\Phi^1(\sum_p w_{Qp}^1\color{red}{x_{p}} + b^1_Q)\right]\in\mathbb{R}^Q$$
</section>

<section>
<h1>Forward, des <span class="red">entrées </span> aux <span class="green">sorties</span></h1>
<img src="./images/Colored_neural_network.svg" height="50%"></img>
$$\color{green}{\tilde{\mathbf{y}}}\leftarrow \left[\Phi^2(\sum_q w_{1q}^2\color{blue}{s^1_q} + b^1_1),\Phi^2(\sum_q w_{2q}^2\color{blue}{s^1_q} + b_2^2)\right]\in\mathbb{R}^2$$
</section>

<section>
<h1>Forward, des <span class="red">entrées </span> aux <span class="green">sorties</span></h1>
<img src="./images/Colored_neural_network_2_anim1.svg" height="50%"></img>
$$\color{red}{\mathbf{x}}\in\mathbb{R}^P$$
</section>

<section>
<h1>Forward, des <span class="red">entrées </span> aux <span class="green">sorties</span></h1>
<img src="./images/Colored_neural_network_2_anim2.svg" height="50%"></img>
$$\color{blue}{\mathbf{s}^1}\leftarrow \left[\Phi^1(\sum_p w_{1p}^1\color{red}{x_{p}} + b^1_1),...,\Phi^1(\sum_p w_{Qp}^1\color{red}{x_{p}} + b^1_Q)\right]\in\mathbb{R}^Q$$
</section>

<section>
<h1>Forward, des <span class="red">entrées </span> aux <span class="green">sorties</span></h1>
<img src="./images/Colored_neural_network_2_anim3.svg" height="50%"></img>
$$\color{blue}{\mathbf{s}^2}\leftarrow \left[\Phi^2(\sum_q w_{1q}^2\color{blue}{s^1_q} + b^1_1),...,\Phi^2(\sum_q w_{Qq}^2\color{blue}{s^1_q} + b^2_q)\right]\in\mathbb{R}^Q$$
</section>

<section>
<h1>Forward, des <span class="red">entrées </span> aux <span class="green">sorties</span></h1>
<img src="./images/Colored_neural_network_2_anim3.svg" height="50%"></img>
$$\color{blue}{\mathbf{s}_{l}} = \Phi^l(\mathbf{W}^l\color{blue}{\mathbf{s}^{(l-1)}})$$
</section>

<section>
<h1>Forward, des <span class="red">entrées </span> aux <span class="green">sorties</span></h1>
<img src="./images/Colored_neural_network_2.svg" height="50%"></img>
$$\color{green}{\tilde{\mathbf{y}}}\leftarrow \left[\Phi^3(\sum_q w_{1q}^2\color{blue}{s^2_q} + b^1_1),\Phi^3(\sum_q w_{2q}^2\color{blue}{s^2_q} + b_2^2)\right]\in\mathbb{R}^2$$
</section>


<section>
<h1>Backward, des <span class="green">sorties</span> aux <span class="red">entrées </span></h1>
$$
\begin{align}
\frac{\delta L(\Phi(\mathbf{W}^3\mathbf{s}^2),y)}{\delta \mathbf{W}^3}&=\color{magenta}{L'(\tilde{y},y)}\color{orange}{\Phi'(\mathbf{W}^3\mathbf{s}^2)}\mathbf{s}^2\\
&=\color{magenta}{\epsilon^3}\mathbf{s}^2
\end{align}
$$
avec $\color{magenta}{\epsilon^3}=\color{magenta}{L'(\tilde{y},y)}\color{orange}{\Phi'(\mathbf{W}^3\mathbf{s}^2)}$
</section>

<section>
<h1>Backward, des <span class="green">sorties</span> aux <span class="red">entrées </span></h1>
$$
\begin{align}
\frac{\delta L(\Phi(\mathbf{W}^3\Phi(\mathbf{W}^2\mathbf{s}^1)),y)}{\delta \mathbf{W}^2}&=\color{magenta}{L'(\tilde{y},y)\Phi'(\mathbf{W}^3\Phi(\mathbf{W}^2\mathbf{s}^1))}\color{orange}{(W^3)^{T}\Phi'(\mathbf{W}^2\mathbf{s}^1)}\mathbf{s}^1\\
&=\color{magenta}{L'(\tilde{y},y)\Phi'(\mathbf{W}^3\mathbf{s}^2)}\color{orange}{(W^3)^{T}\Phi'(\mathbf{W}^2\mathbf{s}^1)}\mathbf{s}^1\\
&=\color{magenta}{\epsilon^3}\color{orange}{(W^3)^{T}\Phi'(\mathbf{W}^2\mathbf{s}^1)}\mathbf{s}^1\\
&=\color{magenta}{\epsilon^2}\mathbf{s}^1
\end{align}
$$
avec $\color{magenta}{\epsilon^2}=\color{magenta}{\epsilon^3}\color{orange}{(W^3)^{T}\Phi'(\mathbf{W}^2\mathbf{s}^1)}$
</section>


<section>
<h1>Backward, des <span class="green">sorties</span> aux <span class="red">entrées </span></h1>
$$
\begin{align}
\frac{\delta L(\Phi(\mathbf{W}^3\Phi(\mathbf{W}^2\Phi(\mathbf{W}^1\mathbf{x}))),y)}{\delta \mathbf{W}^1}&=\color{magenta}{L'(\tilde{y},y)\Phi'(\mathbf{W}^3\mathbf{s}^2)(W^3)^{T}\Phi'(\mathbf{W}^2\mathbf{s}^1)}\color{orange}{(W^2)^{T}\Phi'(\mathbf{W}^1\mathbf{x})}\mathbf{x}\\
&=\color{magenta}{\epsilon^2}\color{orange}{(W^2)^{T}\Phi'(\mathbf{W}^1\mathbf{x})}\mathbf{x}\\
&=\color{magenta}{\epsilon^1}\mathbf{x}
\end{align}
$$
avec $\color{magenta}{\epsilon^1}=\color{magenta}{\epsilon^2}\color{orange}{(W^2)^{T}\Phi'(\mathbf{W}^1\mathbf{x})}$
</section>


<section>
<h1>Backward, des <span class="green">sorties</span> aux <span class="red">entrées </span></h1>
$$\color{magenta}{\epsilon^{L+1}}=L'(\tilde{y},y) $$
Pour $l$ allant de $L$ a 1 :
$$
\begin{align}
\color{magenta}{\epsilon^{l}}&=\color{magenta}{\epsilon^{l+1}}\color{orange}{(\mathbf{W}^{l+1})^T\Phi'(\mathbf{W}^{l}\mathbf{s}^{l-1})}\\
g^{l}_{i.}&=\color{magenta}{\epsilon^{l}}\mathbf{s}^{l-1}
\end{align}
$$
</section>

<section >
<h3>Descente de gradient, différentiation automatique</h3>
<h2 class="red">BP = algorithme de base de la differentiation automatique</h2>
Vrai changement ! </br> 
Introduction de libraries de calcul permetant de construire automatiquement les fonctions efficaces de calcul de gradient. </br>
Extension de BP = Reverse mode automatic differentiation
<ul>
<li> Theano
<li> Torch
<li> TensorFlow
<li> ...
<ul> 
</section>


<section>
<img src="./images/tensorplay.png" width="85%">
<a href="http://playground.tensorflow.org">http://playground.tensorflow.org</a>
</section>



<section >

<h1 class="green">Auto-encoders, Apprentissage non supervisé </h1>

<ul>
<li> objectif reconstruire les entrées 
<li> en compressant l'information au sein d'une couche centrale 
<li> de + faible dimension (bottleneck)
</ul>
<img src="./images/autoencoders.svg" height="60%"/>
</section>




<section >

<h1>Apprentissage non supervisé </h1>
	
<h4 class="green">Auto-encoders</h4>
<ul>
<li> Au final codes = projection non linéaire compressant les entrées 
<li> Même principes d'estimation que pour PMC
<li> Gradient stochastique, ...
<li> Possibilité d'empiler des couches ! complique l'apprentissage
<li> Apprentissage incrémental couches / couches
</ul>
</section>



<section>
<h1 class="green">Keras</h1>
<h1><a href="https://keras.io/">https://keras.io/</a></h1>
</section>

<section >
<h1>Keras</h1>
Libraririe de haut niveau pour définir et apprendre les paramètres d'un réseau </br>
//Interface Séquentielle
<pre><code class="python">model = Sequential()
model.add(Dense(32, activation='relu', input_dim=100))
model.add(Dense(10, activation='softmax'))
model.compile(optimizer='rmsprop',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Generate dummy data
import numpy as np
data = np.random.random((1000, 100))
labels = np.random.randint(10, size=(1000, 1))

# Convert labels to categorical one-hot encoding
one_hot_labels = keras.utils.to_categorical(labels, num_classes=10)

# Train the model, iterating on the data in batches of 32 samples
model.fit(data, one_hot_labels, epochs=10, batch_size=32)
</pre></code>
</section>

<section >
<h1>Keras</h1>
Libraririe de haut niveau pour définir et apprendre les paramètres d'un réseau </br>
//Interface Fonctionelle
<pre><code class="python">from keras.layers import Input, Dense
from keras.models import Model
# This returns a tensor
inputs = Input(shape=(784,))
# a layer instance is callable on a tensor, and returns a tensor
h1 = Dense(64, activation='relu')(inputs)
h2 = Dense(64, activation='relu')(h1)
predictions = Dense(10, activation='softmax')(h2)
# This creates a model that includes
# the Input layer and three Dense layers
model = Model(inputs=inputs, outputs=predictions)
model.compile(optimizer='rmsprop',loss='categorical_crossentropy')
model.fit(data, labels)  # starts training
</pre></code>
</section>


<section>
<h1>Architectures profondes</h1>
<ul>
<li> permet d'extraire automatiquemet des variables pertinentes 
<li> profond > large
<li> <span class="red">! optimisation (vanishing gradient)<span>
<ul>
<img src="./images/Activation_logistic.svg" height="400px">
<span class="red"> disparition du gradient = gradient ~ 0 dans les première couche (ne remonte pas)</span>
</section>

<section style="padding-top:5em;text-align:center">
<h1 class="green">Astuces techniques</h1>
</section>
<section >

<h1>Eviter le sur-apprentissage</h1>
<ul>
<li>Réseau de neuronnes, approximateur universel, capacité forte
<li>Nécessaire d'éviter le sur-apprentissage
</ul></br>
Différentes méthodes, ex :
<ul>
<li> <span class="red">Régularisation</span> : $\sum_{i=1}^NL(G(\mathbf{x}_i,\mathbf{w}),y_i)+\color{green}{\beta\sum_{k=1}^M|w_k|}$
<li> Perturbation   : couche de <span class="red">drop-out</span> </br>(mise a 0 aléatoire de certaine valeurs)
<li> <span class="red">Early-stopping</span> : arrêt de l'optimisation avant convergence complète (en surveillant l'erreur de validation)
</section>


<section >

<h1>Eviter le sur-apprentissage</h1>
Réglage des hyperparamètres :
<h4 class="green">Architecture :</h4>
<ul>
<li> nombre de couchesles
<li> largeur des couches
<li> fonctions d'activations 
<li> paramètres de régularisation
</ul>
<h4 class="green"> Optimisation : </h4>
<ul>
<li> taille des mini-batchs
<li> pas de gradient 
<li> nombre d'époques
</ul>
Utilisation d'une estimation de l'erreur de généralisation </br>(ensemble de validation, validation croisée)
</section>

<section>
<h1>Batch norm</h1>
$$
s = \frac{s-m_s}{\sqrt{\sigma_s^2+\epsilon}}
$$
<ul>
<li> Contrôler la moyenne et la variance des données entre les couches
<li> Chaque entrée est contrôlée de manière indépendantes
<li> Apprentissage : (moyenne, variance) du batch
<li> Test : (moyenne, variance) du jeu de données d'apprentissage complet	
<ul>
</section>


<section>
<h1>Architectures profondes</h1>
 <span class="red">! optimisation (vanishing gradient)</span>
<h2 class="green">Relu</h2>
<img src="./images/Activation_rectified_linear.svg" height="30%">
<h2> + de gradient </h2>
</section>


<section>
<h1>Régularisation, ajout de bruit</h1>
<span class="red">Drop out</span>
<ul>
<li> Durant l'apprentissage, déconnecter aléatoirement à chaque itération des poids avec une probabilité $p$.
<li> Au moment du test, multiplier les poids par leurs fréquence de déconnexion observée 
</ul>
<img src="./images/drop_out1.png" width="30%">
<span class="small">Hinton, G. E., Srivastava, N., Krizhevsky, A., Sutskever, I., & Salakhutdinov, R. R. (2012). Improving neural networks by preventing co-adaptation of
feature detectors. arXiv:1207.0580.</span>
</section>


<section>
<h1>Régularisation, ajout de bruit</h1>
<span class="red">Drop out</span>
<ul>
<li> Durant l'apprentissage, déconnecter aléatoirement à chaque itération des poids avec une probabilité $p$.
<li> Au moment du test, multiplier les poids par leurs fréquence de déconnexion observée 
</ul>
<img src="./images/drop_out2.png" width="30%">
<span class="small">Hinton, G. E., Srivastava, N., Krizhevsky, A., Sutskever, I., & Salakhutdinov, R. R. (2012). Improving neural networks by preventing co-adaptation of
feature detectors. arXiv:1207.0580.</span>
</section>




<section>
<h1>Régularistation</h1>
$$\sum_iL(y_i,G(\mathbf{x}_i,\mathbf{w}))+\lambda\Omega(\mathbf{w})$$
<ul>
<li>L2 : $\Omega(\mathbf{w})=\sum_d||\mathbf{w}_d||$
<li>L1 : $\Omega(\mathbf{w})=\sum_d|\mathbf{w}_d|$
<li>t-Sudent : $\Omega(\mathbf{w})=\sum_d\log(1+\mathbf{w}_d^2)$
</ul>
// prior bayesian
</section>

<section>
<h1>Pré-trainning</h1>
Pré-entrainement non supervisé
<ul>
<li>Utiliser un auto-encoder appris couche par couche
<li>Ne conserver que l'encodeur
<li>Apprendre les couches de sorties 
</ul>
</section>


<section style="padding-top:5em;text-align:center">
<h1>Données particulières images, texte, séquences, série temporelle</h1>
</section>


<section>
<h1>Réseau de neuronnes modernes </h1>
<h4>Architecture modulaire</h4>
capable de traiter différents type de données </br>
<ul>
<li> Couches denses (MLP) 
<li> Couche convolution (Images)
<li> Couche récurrentes (Séquences, temps)
</ul>
<h4>Combinaison ?</h4>
<ul>
<li> Empilement des couches potentiellement de différentes nature
<li> Algorithme d'opitmisation générique (Reverse Mode AD // BP)
</ul>
</section>
<section style="padding-top:5em;text-align:center">
<h1>CNN</h1>
</section>

<section >
<h1>Images</h1>
$\Rightarrow$ convolution, pooling, partage spatial des poids (invariance par translation)
<div style="text-align:center;height:80%" >
<table style="margin:auto;height:80%">
<tr><td>$\begin{bmatrix}0 & 1 & 0\\1 & -4 & 1\\0 & 1 & 0 \end{bmatrix}$</td>
<td><img src="./images/generic-taj-convmatrix-edge-detect.jpg" height="95%"></img></td></tr>
</table>
</div>
</section>

<section>
<h1>Convolution</h1>
partage spatiale des poids, invariance par translation
<img src="./images/convlayer.gif" height="70%"></img>
</section>

<section>
<h1>Convolution</h1>
<img src="./images/conv2layer.gif" height="70%"></img>
</section>

<section>
<h1>Convolution</h1>
partage spatiale des poids, invariance par translation
<img src="./images/cnn.png" height="70%"></img>
</section>


<section>
<h1>Max pooling</h1>
Compression
<img src="./images/maxpool.gif" width="60%"></img>
</section>


<section >
<h1>Images</h1>
$\Rightarrow$ convolution, pooling, partage spatial des poids (invariance par translation)
<img src="./images/convnet.png" width="90%"></img>


<span class="small">LeCun, Y. (1989). Generalization and network design strategies. Connections in Perspective. North-Holland, Amsterdam, 143-55.</br>
LeCun, Y., Kavukcuoglu, K., & Farabet, C. (2010, May). Convolutional networks and applications in vision. In Circuits and Systems (ISCAS),
Proceedings of 2010 IEEE International Symposium on (pp. 253-256). IEEE.</span>
</section>


<section >
<h1>Images</h1>
$\Rightarrow$ convolution, pooling, partage spatial des poids (invariance par translation)
<img src="./images/cnnlecun.png" height="40%"></img>
<span class="small">LeCun, Y. (1989). Generalization and network design strategies. Connections in Perspective. North-Holland, Amsterdam, 143-55.</br>
LeCun, Y., Kavukcuoglu, K., & Farabet, C. (2010, May). Convolutional networks and applications in vision. In Circuits and Systems (ISCAS),
Proceedings of 2010 IEEE International Symposium on (pp. 253-256). IEEE.</span>
</section>

<section>
<h1 class="red">CNN, Architecture type</h1>
Image $\rightarrow\{1,...,K\}$
<ul>
<li> Convolutional blocks (n times)
<ul>
<li>Convolutional layer
<li>Batch normalization
<li>Relu activation
<li>(Subsampling)
</ul>
<li>Dense blocks (n times)
<ul>
<li>Batch normalization
<li>Dense layer (+ weights regularization)
<li>Relu/Tanh activation
</ul>
<li>Dernière couche
<ul>
<li>Batch normalization + Dense + Softmax activation
</ul>
</ul>
</section>

<section>
<h1>res-net</h1>
Principe
Quand une couche a la même taille en entrée et sortie ajouter l'entrée à la sortie.
<img src="images/skip.png" height="40%"></img>
$\rightarrow$ Le gradient peut sauter la couche</br>
$\rightarrow$ aide avec les problème de disparition du gradient
</section>


<section>
<h1>res-net</h1>
<img src="images/skip_net1.png" width="90%"></img>
</section>

<section>
<h1>Dé-Convolution (convolution transposer)</h1>
// up sampling  
<img src="./images/trans-conv.svg" width="85%"></img>
</section>


<section>
<h1>Dé-Convolution</h1>
Segmentation d'image : image $\rightarrow$ image
<img src="./images/imseg.png" height="70%"></img>
</section>


<section>
<h1>Dé-Convolution</h1>
Segmentation d'image : image $\rightarrow$ image
<img src="./images/unet.png" height="70%"></img>
</section>

<section style="padding-top:5em">
<h1 class="green">RNN, LSTM,GRU</h1>
</section>


<section >
<h1>Séquences, séries temporelles</h1>
<h3>Réseau de neuronnes récurrents (RNN)</h3>
LSTM, GRU :</br>
<img src="./images/RNN-unrolled.png" width="50%" style="margin-top:1em">
Une fois déplier // NN classique (poids partagés)
</section>


<section>
<h1>RNN</h1>
<img src="images/rnn/architecture-rnn.png" width="50%"></img>
$$a_t = \Phi(W_{aa}a_{t-1}+W_{ax}x_{t}+b_a)$$
$$y_t = \Phi(W_{ya}a_{t}+b_y)$$
</section>


<section >
<h1>RNN</h1>
<img src="./images/RNN-unrolled.png" width="50%" style="margin-top:1em">
$$L_t = \sum_{t=1}^{T}L(\tilde{y}_i,y_i)$$
<h3>Apprentissage</h3>
<ul>
<li>BPTT : Back Propagation Throught Time 
<li>Gradient = multiplication </br> 
$\rightarrow$ décroître/croître de manière exponentiel en fonction du nombre de couches.
</ul>

</section>


<section >
<h1>RNN</h1>
<img src="./images/RNN-unrolled.png" width="50%" style="margin-top:1em">
$$L_t = \sum_{t=1}^{T}L(\tilde{y}_i,y_i)$$
<h3>Apprentissage</h3>
<ul>
<li>BPTT : Back Propagation Throught Time 
<li>! explosion de gradient (éviter relu)  $g = \frac{th}{||g||}g$
<li>! disparition du gradient
</ul>
</section>


<section>
<h1>RNN, différentes variantes suivant les besoins</h1>
<img src="images/rnn/rnn-many-to-many-same.png" width="50%"></img>
</section>


<section>
<h1>RNN, différentes variantes suivant les besoins</h1>
<img src="images/rnn/rnn-many-to-one.png" width="50%"></img>
Ex: classification de sequences de taille variable (sentiment analysis)
</section>


<section>
<h1>RNN, différentes variantes suivant les besoins</h1>
<img src="images/rnn/rnn-one-to-many.png" width="50%"></img>
Ex : génération de musique 
</section>


<section>
<h1>RNN, différentes variantes suivant les besoins</h1>
<img src="images/rnn/rnn-many-to-many-different.png" width="50%"></img>
Ex : traduction automatique, génération de sous-titre pour des images (image captionning)
</section>

<section>
<h1>RNN, LSTM</h1>
<h2>Mémoire explicite</h2>
<ul>
<li>meilleure prise en compte des dépendances long termes
<li>séparation de la couche cachée temporelle en 2 partie $[c_t,a_t]$
<li>$\rightarrow$ permettre a l'information de remonter le temps plus facilement 
</ul>
<img src="images/rnn/lstm.png" width="50%"></img>
<a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/"> https://colah.github.io/posts/2015-08-Understanding-LSTMs/</a>



</section>


<section>
<h1>RNN, LSTM</h1>
<ul>
<li>introduction de porte pour gérer les deux partie 
$$\Gamma_*(a_t,x_t)=\sigma(\mathbf{w}a_t+\mathbf{u}x_t+b)$$
<li>$\Gamma_f$ porte de facteur d'oublie
<li>$\Gamma_u$,$\Gamma_r$ porte de mise a jour 
<li>$\Gamma_o$ porte de sortie 
</ul>
<img src="images/rnn/lstm.png" width="50%"></img>
<a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/"> https://colah.github.io/posts/2015-08-Understanding-LSTMs/</a>
</section>

<section>
<h1>LSTM</h1>
<h2>Oublier </h2>

<img src="images/rnn/LSTM_detail_forget.png" width="50%"></img>
</section>

<section>
<h1>LSTM</h1>
<h2>Extraire ce qui est pertinent de la nouvelle données</h2>
<img src="images/rnn/LSTM_detail_add.png" width="50%"></img>
</section>


<section>
<h1>LSTM</h1>
<h2>Mettre a jour</h2>
<img src="images/rnn/LSTM3_detail_add2.png" width="50%"></img>
</section>
-

<section>
<h1>LSTM</h1>
<h2>Construire la sortie</h2>
<img src="images/rnn/LSTM_detail_out.png" width="50%"></img>
</section>

<section>
<h1>GRU</h1>
<img src="images/rnn/gru.png" width="50%"></img>
simplification, combiner facteur d'oublie et de mise a jour
</section>



<section style="padding-top:5em">
<h1 class="green">Modèles génératifs</h1>
<h1 class="green">GAN</h1>
</section>


<section>
<h1>Modèles génératifs profonds, GAN, VAE,...</h1>
<h3 class="red">Objectifs :</h3>
<ul>
<li>Estimer un modèle $Q$ a partir de points $p$ tirer suivant une distribution inconnues
<li>Générer de nouveaux points grâce a $Q$
<li>Pas de modèle de la distribution $P$, impossible de calculer une vraisemblance. 
</ul>
<img src="./images/gan/gan_ex.png" width="50%"></img>
<span class="small">Goodfellow, I. (2016). NIPS 2016 Tutorial: Generative Adversarial Networks. arXiv preprint arXiv:1701.00160.</span>
</section>


<section>
<h1>Generateur</h1>
Générer à parir d'un vecteur de petite dimension $z$ un point $\tilde{x}$ dans un espace de grande dimension (ex: image)
<img src="./images/gan/generator.png" width="50%"></img>
</section>


<section>
<h1>Auto-encoder</h1>
<img src="./images/gan/diabolo.png" height="30%"></img>
$$L(\phi,\theta,\mathbf{x})=-\mathbb{E}_{q_\phi(z|x)}\log(p_{\theta}(\mathbf{x}|\mathbf{z}))$$
<h3 class="green">idée !</h3>
<ul>
<li>Utiliser le décodeur
<li>Problème pas de contrôle sur la distribution de $z$
</ul>
</section>



<section>
<h1>Variational Auto Encoder</h1>
$$L(\phi,\theta,\mathbf{x})=-\mathbb{E}_{q_\phi(z|x)}\log(p_{\theta}(\mathbf{x}|\mathbf{z}))+D_{KL}(q_\phi(\mathbf{z}|\mathbf{x})|p_\theta(z))$$
<img src="./images/gan/vae.png" height="30%"></img>
<ul>
<li>Ajouter un terme pour que la distribution de $z$ soit proche d'une distribution cible
<li>Typiquement distribution Gaussienne multivariée de moyenne nulle et de matrice de variance covariance égale à l'identité
<li>$D_{KL}$ permet de mesurer l'écart entre deux distribution !! non symétrique (liens avec la vraisemblance)
</ul>
<h3 class="red">Problème $p(\mathbf{z})$ multimodale ??</h3>
<span class="small">
Kingma, Diederik P., and Max Welling. ”Auto-encoding variational bayes.” arXiv preprint arXiv:1312.6114 (2013).
</span>
</section>



<section>
<h1>GAN</h1>
Un jeux a 2 joueurs, chaque joueurs est un réseau de neuronnes
<ul>
<li>Un <span class="red">Discriminateur D</span> essaye de disciminer les exemple réels $x$ de ceux générer par $G$ :  $\tilde{x}$
<li>Un <span class="red">Générateur G</span> essaye de tromper D
</ul>
<img src="./images/gan/gan.png" width="50%"></img>
</section>


<section>
<h1>GAN</h1>
Un jeux a 2 joueurs, chaque joueurs est un réseau de neuronnes

$$L(\omega,\theta)=-\frac{1}{2}\mathbb{E}_{x\sim P}log(D_\omega(x))-\frac{1}{2}\mathbb{E}_{\mathbf{z}\sim Z}log(1-D_\omega(G_\theta(\mathbf{z})))$$
<ul>
<li>Discriminateur (disciminer les exemple réels $x$ de ceux générer par $G$ $\tilde{x}$)</br>
Minimiser L(ω, θ) en ω avec $\theta$ fixer.</br>
$\rightarrow$ cross entropy classique.</br>
<li>G essaye de tromper D</br>
Maximiser L(ω, θ) en θ avec ω fixer.
</ul></br>
<span class="green"> (Zero-Sum Game) Equilibre de Nash // propriété théorique</span></br>
<span class="red"> Optimsation pas si facile </span></br>
<span class="small">
Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Bengio, Y. (2014). Generative adversarial nets. In Advances in neural
information processing systems (pp. 2672-2680)
</span>
</section>

<section>
<h1>dcGAN</h1>
Exemple de générateur pour des images
<img src="./images/gan/dcgan.png" width="50%"></img>
</section>


<section>
<h1>dcGAN</h1>
Exemple de sorties
<img src="./images/gan/dcgan_ex.png" width="50%"></img>
</section>


<section>
<h1>dcGAN</h1>
Exemple de sorties
<img src="./images/gan/thispersondne.png" width="50%"></img>
</section>

<section>
<h1>GAN et variante</h1>
<img src="./images/gan/gan_small.png" width="50%"></img>
</section>

<section>
<h1>Conditional GAN</h1>
<img src="./images/gan/cgan.png" width="50%"></img>
<span class="small">
Mirza, M., Osindero, S. (2014). Conditional generative adversarial nets. arXiv preprint arXiv:1411.1784</br>
Reed, S., Akata, Z., Yan, X., Logeswaran, L., Schiele, B., Lee, H. (2016, May). Generative adversarial text to image synthesis. In Proceedings of The
33rd International Conference on Machine Learning (Vol. 3).</span>
</section>



<section>
<h1>Conditional GAN</h1>
Exemple de sorties
<img src="./images/gan/cgan_ex.png" height="50%"></img>
</section>




<section>
<h1>Adversarial Auto Encoder</h1>
<img src="./images/gan/aae.png" width="50%"></img>
$$L = L_{adv} + L_{rec}$$
<span class="small">Makhzani et al. “Adversarial Autoencoders”. 2015</span>
</section>



<section>
<h1>Espace latent</h1>
<img src="./images/gan/latentspace.png" width="50%"></img>
<span class="small">Radford, A., Metz, L., Chintala, S. (2015). Unsupervised representation learning with deep convolutional generative adversarial networks. arXiv
preprint arXiv:1511.06434.</span>
</section>


<section>
<h1>Pix2pix</h1>
Condition = image + Adversarial Auto Encoder
<img src="./images/gan/pix2pix1.png" width="50%"></img>
<span class="small">Isola, P., Zhu, J. Y., Zhou, T., Efros, A. A. (2016). Image-to-image translation with conditional adversarial networks. arXiv preprint arXiv:1611.07004.</span>
</section>


<section>
<h1>Pix2pix</h1>
Condition = image + Adversarial Auto Encoder
<img src="./images/gan/pix2pix2.jpg" width="50%"></img>
<span class="small">Isola, P., Zhu, J. Y., Zhou, T., Efros, A. A. (2016). Image-to-image translation with conditional adversarial networks. arXiv preprint arXiv:1611.07004.</span>
</section>


<section>
<h1>Pix2pix</h1>
Condition = image + Adversarial Auto Encoder
<img src="./images/gan/pix2pix3.jpg" width="50%"></img>
<span class="small">Isola, P., Zhu, J. Y., Zhou, T., Efros, A. A. (2016). Image-to-image translation with conditional adversarial networks. arXiv preprint arXiv:1611.07004.</span>
</section>


<section style="padding-top:5em ">
<h1>Self supervised learning</h1>
$$\{\mathbf{x}_1,...,\mathbf{x}_n\}\rightarrow \{(\mathbf{x}_1,\tilde{y}_1),...,(\mathbf{x}_n,\tilde{y}_n)\}\rightarrow\,f(\mathbf{x})\approx \tilde{y}$$
</section>

<section>
<h1>Transfert d'apprentissage</h1>
<ul>
<li>Utiliser les première couches d'un réseau entrainé sur une autre tache
<li>"Finetuning" des dernière couches sur la tâche cible. 
</ul>
<img src="./images/transfert.png" width="40%">
</section>

<section >
<h1>Self supervised learning</h1>
<ul>
<li> Apprendre un réseau avec une tache pretexte </br>
<span class="red">! (construite sans labels mais supervisé) </span>
<li>"Finetuning" des dernière couches sur la tâche cible. 
</ul>
<img src="./images/pretext_selfsup2.png" height="60%">
</section>

<section >
<h1>Self supervised learning</h1>
<ul>
<li> Apprendre un réseau avec une tache pretexte </br>
<span class="red">! (construite sans labels mais supervisé) </span>
<li>"Finetuning" des dernière couches sur la tâche cible. 
</ul>
<img src="./images/colorisation.png" width="60%">
<h3>Colorisation</h3>
</section>

<section >
<h1>Self supervised learning</h1>
<ul>
<li> Apprendre un réseau avec une tache pretexte </br>
<span class="red">! (construite sans labels mais supervisé) </span>
<li>"Finetuning" des dernière couches sur la tâche cible. 
</ul>
<img src="./images/pretext_selfsup.png" height="60%">
</section>
<section >
<h1>Self supervised learning</h1>
<ul>
<li> Apprendre un réseau avec une tache pretexte </br>
<span class="red">! (construite sans labels mais supervisé) </span>
<li>"Finetuning" des dernière couches sur la tâche cible. 
</ul>
<img src="./images/patch.png" height="60%">
<h3>Patchs spatial configuration</h3>
</section>



<section >
<h1>Texte, WordEmbedding</h1>
<img src="./images/wordembedding.png" height="75%" style="margin-top:1em">
</section>

<section>
 WordEmbedding>
<h1>Texte, WordEmbedding</h1>
Prédire le prochain mots

<img src="./images/nn_language_model-1.jpg" height="55%" style="margin-top:1em">
Bengio, Y., Ducharme, R., Vincent, P., & Janvin, C. (2003). A Neural Probabilistic Language Model. The Journal of Machine Learning Research, 3, 1137–1155. Retrieved from http://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf ↩︎
</section>

<section>
<h1>Texte, WordEmbedding</h1>
Prédire le prochain mots:

<ul>
<li> <b>Embedding Layer</b>: produit le word embeding index vector . word embeding matrix</br>
<li> <b>Intermediate Layer(s)</b>: consrtuction de représentation inetrmédiaires, e.g. a couches denses prenant en entrée la concatenation des embeddings des mots précedents;</br>
<li> <b>Softmax Layer</b>: couche de décision produit une probabilité sur le vocabulaire V</br>
</ul>
</section>




<section>
<h1>Texte, WordEmbedding, CBOW</h1>
Prédire un mot a partir de son contexte:

<img src="./images/cbow.png" height="55%" style="margin-top:1em">
Mikolov, T., Corrado, G., Chen, K., & Dean, J. (2013). Efficient Estimation of Word Representations in Vector Space. Proceedings of the International Conference on Learning Representations (ICLR 2013), 1–12. ↩︎

</section>

<section>
<h1>Texte, WordEmbedding, CBOW</h1>
Prédire un mot a partir de son contexte:
<ul>
<li> <b>Embedding Layer</b>:: produit le word embeding index vector . word embeding matrix;
<li> <b>Intermediate Layer(s)</b>: une simple moyenne des embeddings du contexte 
<li> <b>Softmax Layer</b>: couche de décision produit une probabilité sur le vocabulaire V
</ul>
</section>

<section>
<h1>Texte, WordEmbedding, CBOW</h1>
D'un point de vue computationel la dernière couche de soft-max coute cher (|V| est grand)
$$p(w|c)=\frac{\exp(h^{t}v_{w})}{\sum_{w_i\in V}\exp(h^{t}v_{w_{i}})}$$
Idée modifier le problème 
-> liens "Contrastive learning" / reformuler la loss sur des paires
</section>


</section>
<section>
<h1>Texte CBOW + Negative sampling</h1>
<h3>Tâche pretexte : Mots proche // Mots distants</h3>
$\Rightarrow$ one-hot encoding, position dans le dictionaire $(0,0,...,1,...,0,0)$
<h4>Exemple wordEmbeding :</h4> 
<ul>
<li> $\mathbf{z}_1 = \mathbf{x}_1^t\mathbf{V}$
<li> $\mathbf{z}_2 = \mathbf{x}_2^t\mathbf{V}$
<li> $s = \frac{\mathbf{z}_1^t\mathbf{z}_2}{||\mathbf{z}_1||||\mathbf{z}_2||}$
<li> $y = sigmoid(s)$
</ul>
</br>
<h4>Construction du jeu de données d'apprentissage :</h4>
<ul>
<li>couples de mots $(\mathbf{x}_1,\mathbf{x}_2)$ présent dans la même fenêtre ($y=1$)
<li>couples de mots $(\mathbf{x}_1,\mathbf{x}_2)$ aléatoires ($y=0$)
</ul>
$\Rightarrow \mathbf{V}$ position des mots dans l'espace de projection  
</section>


<section>
<h1>Texte CBOW + Negative sampling</h1>
Tâche pretexte :
<h3>Tâche pretexte : Mots proche // Mots distants</h3>
<h4>Construction du jeu de données d'apprentissage :</h4>
<ul>
<li>couples de mots $(\mathbf{x}_1,\mathbf{x}_2)$ présent dans la même fenêtre ($y=1$)
<li>couples de mots $(\mathbf{x}_1,\mathbf{x}_2)$ aléatoires ($y=0$)
</ul>
$\Rightarrow \mathbf{W}$ position des mots dans l'espace de projection  
<h4>Construction des exemples</h4>
<ul>
<li> Nombre d'exemple négatif / exemple positif <i>(nb_neg)</i>
<li> Tirage des mots négatif (distribution empirique lissée, $\alpha$) 
$$ps_{w_i}^\alpha= \frac{\#w_i^{\alpha}}{\sum_j\#w_j^\alpha}$$
<li> Sous-échantillonage des mots fréquents ($t$)
$$ pr_{w_i} = 1 -\sqrt(\frac{t}{ps_{w_i}^1})$$
</ul>
</section>


<section>
<h1> Liens ressources </h1>

& credits images 

<ul>
<li><a href="https://www.tensorflow.org/tutorials">https://www.tensorflow.org/tutorials</a>

<li> <a href="https://stanford.edu/~shervine/teaching/cs-230/"> standford cs230 </a>

<li> <a href="https://atcold.github.io/pytorch-Deep-Learning/"> course lecun </a>
 
<li> <a href="https://moodle.insa-rouen.fr/course/view.php?id=1207">insa rouen </a>

<li><a href="https://drive.google.com/file/d/1e_9W8q9PL20iqOR-pfK89eILc_VtYaw1/view"> Gradient-based Optimization in deep learning </a>


</ul>


</section>




<script src="./library/d3.v3.min.js"></script>
<script src="./library/stack.v1.min.js"></script>
<link rel="stylesheet" href="./library/styles/hybrid.css">
<script src="./library/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script>

var mystack = stack()
    .on("activate", activate)
    .on("deactivate", deactivate);

var section = d3.selectAll("section"),
    follow = d3.select("#follow"),
    followAnchor = d3.select("#follow-anchor"),
    lorenz = d3.select("#lorenz"),
    followIndex = section[0].indexOf(follow.node()),
    lorenzIndex = section[0].indexOf(lorenz.node());

function refollow() {
  followAnchor.style("top", (followIndex + (1 - mystack.scrollRatio()) / 2 - d3.event.offset) * 100 + "%");
}

function activate(d, i) {
  if (i === followIndex) mystack.on("scroll.follow", refollow);
  if (i === lorenzIndex) startLorenz();
}

function deactivate(d, i) {
  if (i === followIndex) mystack.on("scroll.follow", null);
  if (i === lorenzIndex) stopLorenz();
}


</script>
